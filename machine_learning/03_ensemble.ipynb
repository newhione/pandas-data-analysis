{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d1112de",
   "metadata": {},
   "source": [
    "# 다양한 모델을 결합한 앙상블\n",
    "- 앙상블\n",
    "- 다수결 투표 앙상블(Voting)\n",
    "- 배깅(Bagging)\n",
    "- 그래이언트 부스팅 & XGBoost\n",
    "- 모델성능 평가 및 비교\n",
    "\n",
    "단일모델의 한계\n",
    "- 과대적합, 과소적합\n",
    "- 높은 분산\n",
    "- 높은 편향\n",
    "\n",
    "---\n",
    "\n",
    "## 앙상블 (집단지성)\n",
    "- 배경: 같은 알고리즘, 다른 데이터셋(Bootstrap)  `RandomForest` 분산감소\n",
    "- 부스팅: 순차적으로 약한 학습기를 강화           `AdaBoost`, `XGBoost` 편향감소\n",
    "- 스태깅: 다른 알고리즘을 메타 모델로 학습        `Stacked Generalization` 일반화 성능\n",
    "\n",
    "### 1. Voting\n",
    "- `Hard Voting`: 다수결 투표\n",
    "- `Soft Voting`: 가중치 투표 - 확률을 보고 결정함. 보통 Hard Voting보다 성능이 좋음\n",
    "### 2. Bagging\n",
    "- `Bootstrap Aggregation`\n",
    "- `Bootstrap`: 원본 데이터 1000개 중 중복을 허용해 1000번을 뽑아, 훈련세트 만들기\n",
    "- `Aggregation`: 순차적으로 학습하고난 후 여러개의 모델들을 투표해 최종결론 내리기\n",
    "- 대표모델: `RandomForest`\n",
    "- 효과: 과적합 방지 = 모델의 분산을 줄임\n",
    "### 3. Boosting\n",
    "**앞선 모델의 오답을 보완하면서 순차적으로 학습하는 방식**\n",
    "> 1. 모델 1 (기본 학습)\n",
    "- 전체 데이터를 학습하고 예측 수행  \n",
    "- 오답(틀린 샘플)을 식별  \n",
    ">  2. 가중치 조정\n",
    "- 모델 1이 틀린 데이터에 **더 높은 가중치(중요도)** 부여  \n",
    "> 3. 모델 2 (보완 학습)\n",
    "- 가중치가 높은, 즉 **틀리기 쉬운 데이터**에 더 집중하여 학습  \n",
    "> 4. 모델 3 이후 (반복 보완)\n",
    "- 이전 모델(모델 1, 2)이 공통으로 틀린 문제에 집중  \n",
    "- 오답에 다시 가중치 부여 → 반복적으로 학습 성능 개선  \n",
    "> 5. 최종 단계 (결합)\n",
    "- 각 모델의 예측 결과를 **가중 평균(Weighted Average)** 으로 결합  \n",
    "- **성능이 좋은 모델일수록 가중치↑**  \n",
    "- 이를 통해 **편향(Bias)을 줄이고 예측 성능 향상**\n",
    "\n",
    "### 4. Stacking\n",
    "- 1 base model: 여러개의 모델 훈련\n",
    "- 2 meta model:\n",
    "    - 1단계 모델들이 예측한 값들을 모음\n",
    "    - 예측한 값을 훈련데이터(특성)로 사용\n",
    "- 결론:\n",
    "    - 새로운 데이터를 최종모델(Meta-model)(ex.로지스틱회귀) 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d49936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([249, 251]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 데이터 생성\n",
    "X,y = make_classification(n_samples=500, n_features=2, random_state=42, n_redundant=0)\n",
    "np.unique(y,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ea6bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n",
      "0.89\n",
      "0.93\n",
      "0.9\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "This 'SVC' has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\python_src\\.venv\\Lib\\site-packages\\sklearn\\utils\\_available_if.py:32\u001b[39m, in \u001b[36m_AvailableIfDescriptor._check\u001b[39m\u001b[34m(self, obj, owner)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     check_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\python_src\\.venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:831\u001b[39m, in \u001b[36mBaseSVC._check_proba\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    830\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.probability:\n\u001b[32m--> \u001b[39m\u001b[32m831\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    832\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpredict_proba is not available when probability=False\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    833\u001b[39m     )\n\u001b[32m    834\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._impl \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mc_svc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mnu_svc\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[31mAttributeError\u001b[39m: predict_proba is not available when probability=False",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     23\u001b[39m models = [\n\u001b[32m     24\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m,lr),\n\u001b[32m     25\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33msvm\u001b[39m\u001b[33m'\u001b[39m,svm),\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mvoting_soft\u001b[39m\u001b[33m'\u001b[39m,voting_soft)\n\u001b[32m     29\u001b[39m ]\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m label, model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\python_src\\.venv\\Lib\\site-packages\\sklearn\\base.py:548\u001b[39m, in \u001b[36mClassifierMixin.score\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    524\u001b[39m \u001b[33;03mReturn :ref:`accuracy <accuracy_score>` on provided data and labels.\u001b[39;00m\n\u001b[32m    525\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    544\u001b[39m \u001b[33;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[32m    545\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, sample_weight=sample_weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\python_src\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:422\u001b[39m, in \u001b[36mVotingClassifier.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    420\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.voting == \u001b[33m\"\u001b[39m\u001b[33msoft\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m     maj = np.argmax(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, axis=\u001b[32m1\u001b[39m)\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# 'hard' voting\u001b[39;00m\n\u001b[32m    425\u001b[39m     predictions = \u001b[38;5;28mself\u001b[39m._predict(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\python_src\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:463\u001b[39m, in \u001b[36mVotingClassifier.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute probabilities of possible outcomes for samples in X.\u001b[39;00m\n\u001b[32m    450\u001b[39m \n\u001b[32m    451\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    459\u001b[39m \u001b[33;03m    Weighted average probability for each class per sample.\u001b[39;00m\n\u001b[32m    460\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    461\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    462\u001b[39m avg = np.average(\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_collect_probas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, axis=\u001b[32m0\u001b[39m, weights=\u001b[38;5;28mself\u001b[39m._weights_not_none\n\u001b[32m    464\u001b[39m )\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m avg\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\python_src\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:438\u001b[39m, in \u001b[36mVotingClassifier._collect_probas\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_collect_probas\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    437\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Collect results from clf.predict calls.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.asarray([\u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m(X) \u001b[38;5;28;01mfor\u001b[39;00m clf \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.estimators_])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\python_src\\.venv\\Lib\\site-packages\\sklearn\\utils\\_available_if.py:43\u001b[39m, in \u001b[36m_AvailableIfDescriptor.__get__\u001b[39m\u001b[34m(self, obj, owner)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__get__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj, owner=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     41\u001b[39m         \u001b[38;5;66;03m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[32m     42\u001b[39m         \u001b[38;5;66;03m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mowner\u001b[49m\u001b[43m=\u001b[49m\u001b[43mowner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m         out = MethodType(\u001b[38;5;28mself\u001b[39m.fn, obj)\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     47\u001b[39m         \u001b[38;5;66;03m# This makes it possible to use the decorated method as an unbound method,\u001b[39;00m\n\u001b[32m     48\u001b[39m         \u001b[38;5;66;03m# for instance when monkeypatching.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\python_src\\.venv\\Lib\\site-packages\\sklearn\\utils\\_available_if.py:34\u001b[39m, in \u001b[36m_AvailableIfDescriptor._check\u001b[39m\u001b[34m(self, obj, owner)\u001b[39m\n\u001b[32m     32\u001b[39m     check_result = \u001b[38;5;28mself\u001b[39m.check(obj)\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(attr_err_msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_result:\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(attr_err_msg)\n",
      "\u001b[31mAttributeError\u001b[39m: This 'SVC' has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "# 훈련/테스트 데이터 나누기\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 개별모델 생성\n",
    "lr = LogisticRegression(random_state=42)\n",
    "svm = SVC(random_state=42, probability=True)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "svm.fit(X_train,y_train)\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Voting 앙상블\n",
    "voting_hard = VotingClassifier(estimators=[('lr',lr),('svm',svm),('knn',knn)], voting='hard')\n",
    "voting_soft = VotingClassifier(estimators=[('lr',lr),('svm',svm),('knn',knn)], voting='soft')\n",
    "\n",
    "voting_hard.fit(X_train,y_train)\n",
    "voting_soft.fit(X_train,y_train)\n",
    "\n",
    "models = [\n",
    "    ('lr',lr),\n",
    "    ('svm',svm),\n",
    "    ('knn',knn),\n",
    "    ('voting_hard',voting_hard),\n",
    "    ('voting_soft',voting_soft)\n",
    "]\n",
    "\n",
    "\n",
    "for label, model in models:\n",
    "    print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72386b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41d6301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab0fdc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
